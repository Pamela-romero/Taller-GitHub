
#  Detecci贸n de Fraude en Seguros de Autom贸viles

Este proyecto tiene como objetivo identificar posibles fraudes en reclamos de seguros de autom贸viles utilizando t茅cnicas de Machine Learning. Se emplean varios modelos, se tratan los datos desbalanceados, y se optimizan hiperpar谩metros para mejorar el desempe帽o.

---

##  1. Selecci贸n de Caracter铆sticas

```python
features = [ ... ]
```

Se define una lista de caracter铆sticas que ser谩n utilizadas como variables predictoras. Estas incluyen variables ordinales, categ贸ricas codificadas (one-hot) y binarias.

---

##  2. Modelos de Clasificaci贸n

```python
model1 = DecisionTreeClassifier(...)
model2 = KNeighborsClassifier()
model3 = XGBClassifier(...)
model4 = SVC(...)
```

Se crean cuatro modelos de clasificaci贸n distintos para luego integrarlos en un ensamblado con VotingClassifier:
- rbol de decisi贸n
- K-Vecinos m谩s cercanos
- XGBoost (modelo base robusto)
- SVM (con probabilidades activadas)

---

##  3. Ensamblado con VotingClassifier

```python
voting_clf = VotingClassifier(estimators=[...], voting='soft')
```

Se construye un modelo de ensamblado que utiliza votaci贸n **soft**, lo que significa que se consideran las probabilidades de predicci贸n de cada modelo para hacer una predicci贸n final. Esto tiende a mejorar el rendimiento si los modelos base son diversos.

---

##  4. Evaluaci贸n Inicial de Modelos

```python
classification_report(...)
```

Se eval煤an individualmente los modelos dentro del ensamble utilizando el conjunto de entrenamiento. Se imprime la precisi贸n, recall y F1-score para entender c贸mo se comportan con datos desbalanceados (clase minoritaria: fraude).

---

## 锔 5. Manejo del Desbalanceo

```python
smote = SMOTE(...)
X_resampled, y_resampled = smote.fit_resample(...)
```

Se utiliza SMOTE para sobresamplear la clase minoritaria (fraude). Esto busca mejorar la capacidad del modelo para aprender patrones de esta clase y reducir falsos negativos.

---

## 锔 6. Ajuste de Hiperpar谩metros con GridSearchCV

```python
grid_search = GridSearchCV(...)
```

Se entrena un modelo **XGBoost** ajustando autom谩ticamente sus hiperpar谩metros con `GridSearchCV`, optimizando para el F1-score macro. Se calcula `scale_pos_weight` para ajustar el desequilibrio de clases.

---

## И 7. Evaluaci贸n del Modelo ptimo

```python
classification_report(...)
```

Con los mejores par谩metros, se eval煤a el modelo sobre el conjunto de validaci贸n. Se ajusta el umbral de clasificaci贸n (`0.35`) para mejorar el recall de la clase minoritaria.

---

##  8. Importancia de Caracter铆sticas

```python
importances = best_model.feature_importances_
```

Se identifican las variables m谩s influyentes en las predicciones del modelo, lo cual ayuda a interpretar c贸mo toma decisiones el modelo y a posibles mejoras del dataset.

---

##  9. Matriz de Confusi贸n

```python
confusion_matrix(...)
ConfusionMatrixDisplay(...).plot()
```

Se visualiza la matriz de confusi贸n para evaluar el rendimiento en t茅rminos de verdaderos positivos/negativos y falsos positivos/negativos. til para ver errores de clasificaci贸n en detalle.

---

##  Requisitos

- Python 3.8+
- scikit-learn
- imbalanced-learn
- xgboost
- pandas
- matplotlib

---

